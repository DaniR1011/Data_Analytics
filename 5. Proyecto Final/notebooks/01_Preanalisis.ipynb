{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 1. Preanálisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Importamos Pandas con el alias que decidamos y cargamos nuestro primer archivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"../data/raw_data/clubs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Cargamos nuestro segundo archivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"../data/raw_data/club_games.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Realizamos el análisis de ambos archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el número de filas y de columnas\n",
    "num_filas, num_columnas = df1.shape\n",
    "print(f\"El primer dataset csv tiene {num_filas} filas y {num_columnas} columnas.\")\n",
    "\n",
    "num_filas, num_columnas = df2.shape\n",
    "print(f\"El segundo dataset csv tiene {num_filas} filas y {num_columnas} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Analizamos las columnas que tiene cada archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspeccionamos las columnas de cada DataFrame\n",
    "print(\"Columnas en el archivo CSV 1:\")\n",
    "print(df1.columns)\n",
    "\n",
    "print(\"Columnas en el archivo CSV 2:\")\n",
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Obtenemos la columna 'club_id' como coincidente. Verificamos si existen o no valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que la columna id, no contiene valores nulos, para que la unión se produzca correctamente.\n",
    "print(df1['club_id'].isnull().sum())\n",
    "print(df2['club_id'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Analizamos valores nulos y eliminamos esas columnas, para evitar conflictos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos los valores nulos\n",
    "df2 = df2.dropna(subset=[\"club_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Verificamos que no existen valores nulos en la columna coincidente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que la columna id, no contiene valores nulos, para que la unión se produzca correctamente.\n",
    "print(df1['club_id'].isnull().sum())\n",
    "print(df2['club_id'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Comprobamos que las columnas clave no contienen valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De esta manera, mejoramos y optimizamos la eficiencia de nuestro set de datos\n",
    "print(df1.duplicated().sum())\n",
    "print(df2.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Obtenemos la columna 'club_id' como coincidente. Verificamos el tipo de dato de la columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos que las columnas que vamos a combinar, sean del mismo tipo de dato para que no genere problemas.\n",
    "print(df1['club_id'].dtype)\n",
    "print(df2['club_id'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Cambiamos el tipo de dato de df2 a int, para que coincida con el de df1. Modificando a int, evitamos decimales en nuestra columna clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"club_id\"] = df2[\"club_id\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Verificamos que el tipo de dato ha sido modificado correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos que las columnas que vamos a combinar, sean del mismo tipo de dato para que no genere problemas.\n",
    "print(df1['club_id'].dtype)\n",
    "print(df2['club_id'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Decidimos hacer un merge, puesto que solo coincide una columna entre los dos archivos, y queremos traer toda la información restante. Realizamos el merge entre el dataframe csv y el de excel, a través de la columna 'club_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la unión a través de un inner join, puesto que queremos combinar los archivos a través de la columna id_, y que el resto de información coincidente aparezca en el resultado final.\n",
    "df = pd.merge(df1, df2, on=\"club_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Transformamos el dataframe final en un csv, y lo cremoa en la carpeta adecuada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificamos la carpeta exacta donde guardaremos el archivo\n",
    "ruta_carpeta = '../data/transform_data/'\n",
    "\n",
    "# Creamos el archivo CSV en la carpeta especificada\n",
    "df.to_csv(f'{ruta_carpeta}/transform_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. Realizamos el preanálisis final con las funciones que aloja Pandas, verificando que los datos se han combinado correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El .head() nos permite obtener una visualización previa de las 5 primeras filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El .info() nos aporta información sobre el tipo de dato de cada columna\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el tipo de dato de cada columna\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos si existen valores nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el número de filas y de columnas final, comprobando que no hemos perdido información\n",
    "num_filas, num_columnas = df.shape\n",
    "print(f\"El dataset combinado tiene {num_filas} filas y {num_columnas} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones del Preanálisis\n",
    "\n",
    "1. **Completitud de los datos**:<br>\n",
    "   El conjunto de datos tiene valores nulos, que deben ser reemplazados en función de la columna que corresponda (numérica o categórica),\n",
    "   para que no modifique los valores finales.<br><br>\n",
    "\n",
    "2. **Tipos de datos**:<br>\n",
    "   Las columnas clave que nos van a permitir realizar la unión, tienen el mismo tipo de dato.<br><br>\n",
    "\n",
    "3. **Duplicados**:<br>\n",
    "   No se encontraron filas duplicadas ni en el archivo, ni en las columnas clave, por lo que la unión se puede realizar correctamente.<br><br>\n",
    "\n",
    "4. **Estructura de los datos**:<br>\n",
    "   El archivo contiene **120099 filas** y **27 columnas**. Las columnas parecen ser coherentes y contienen información relevante para el análisis posterior.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 1. Preanálisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Importamos pandas con el alias que decidamos y cargamos nuestro archivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_csv = pd.read_csv('../data/raw_data/bank_additional.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Cargamos nuestro archivo Excel y leemos todas las hojas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_excel = {sheet: pd.read_excel('../data/raw_data/customer_details.xlsx', sheet_name=sheet) \n",
    "            for sheet in pd.ExcelFile('../data/raw_data/customer_details.xlsx').sheet_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Combinamos las tres hojas del Excel en una única"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_combined = pd.concat(dfs_excel.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Verificamos el tipo de dato de las columnas clave que vamos a combinar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos que las columnas que vamos a combinar, sean del mismo tipo de dato.\n",
    "print(df_csv['id_'].dtype)\n",
    "print(df_excel_combined['ID'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Comprobamos que las columnas clave no contienen valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que la columna id, no contiene valores nulos, para que la unión se produzca correctamente.\n",
    "print(df_csv['id_'].isnull().sum())\n",
    "print(df_excel_combined['ID'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Verificamos que las columnas clave no contienen valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De esta manera, mejoramos y optimizamos la eficiencia de nuestro set de datos\n",
    "print(df_csv.duplicated().sum())\n",
    "print(df_excel_combined.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Analizamos que el archivo excel, contiene una columna que se llama ID, la cual modificaremos de nombre a id_ , para que coincida con la del csv, y poder realizar el merge entre los dos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_combined.rename(columns={'ID': 'id_'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Realizamos el merge entre el dataframe csv y el de excel, a través de la columna ' id_ '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_csv, df_excel_combined], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Transformamos el dataframe final en un csv, y lo creamos en la carpeta adecuada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificamos la carpeta exacta donde guardaremos el archivo\n",
    "ruta_carpeta = '../data/transform_data'\n",
    "\n",
    "# Creamos el archivo CSV en la carpeta especificada\n",
    "df.to_csv(f'{ruta_carpeta}/transform_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Realizamos el preanálisis con las funciones que aloja Pandas: (.head(), .info(), .dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El .head() nos permite obtener una visualización previa de las 5 primeras filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El .info() nos aporta información sobre el tipo de dato de cada columna\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el tipo de dato de cada columna\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos si existen valores nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el número de filas y de columnas\n",
    "num_filas, num_columnas = df.shape\n",
    "print(f\"El dataset combinado tiene {num_filas} filas y {num_columnas} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones del Preanálisis\n",
    "\n",
    "1. **Completitud de los datos**:<br>\n",
    "   El conjunto de datos tiene valores nulos, que deben ser reemplazados en función de la columna que corresponda (numérica o categórica),\n",
    "   para que no modifique los valores finales.<br><br>\n",
    "\n",
    "2. **Tipos de datos**:<br>\n",
    "   Las columnas clave que nos van a permitir realizar la unión, tienen el mismo tipo de dato.<br><br>\n",
    "\n",
    "3. **Duplicados**:<br>\n",
    "   No se encontraron filas duplicadas ni en el archivo, ni en las columnas clave, por lo que la unión se puede realizar correctamente.<br><br>\n",
    "\n",
    "4. **Estructura de los datos**:<br>\n",
    "   El archivo contiene **86179 filas** y **29 columnas**. Las columnas parecen ser coherentes y contienen información relevante para el análisis posterior.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

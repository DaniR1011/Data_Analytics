{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 1. Preanálisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Importamos pandas con el alias que decidamos y cargamos nuestro archivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_csv = pd.read_csv('../data/raw_data/bank_additional.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Cargamos nuestro archivo Excel y leemos todas las hojas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_excel = {sheet: pd.read_excel('../data/raw_data/customer_details.xlsx', sheet_name=sheet) \n",
    "            for sheet in pd.ExcelFile('../data/raw_data/customer_details.xlsx').sheet_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Combinamos las tres hojas del Excel en una única"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_combined = pd.concat(dfs_excel.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Realizamos el análisis de ambos archivos (csv y xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el número de filas y de columnas\n",
    "num_filas, num_columnas = df_csv.shape\n",
    "print(f\"El dataset csv tiene {num_filas} filas y {num_columnas} columnas.\")\n",
    "\n",
    "num_filas, num_columnas = df_excel_combined.shape\n",
    "print(f\"El dataset xlsx tiene {num_filas} filas y {num_columnas} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Analizamos las columnas que contiene cada archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspeccionar columnas de cada DataFrame\n",
    "print(\"Columnas en el archivo CSV:\")\n",
    "print(df_csv.columns)\n",
    "\n",
    "print(\"Columnas en el archivo Excel:\")\n",
    "print(df_excel_combined.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Obtenemos la columna ID como coincidente. Verificamos el tipo de dato de la columna ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos que las columnas que vamos a combinar, sean del mismo tipo de dato para que no genere problemas.\n",
    "print(df_csv['id_'].dtype)\n",
    "print(df_excel_combined['ID'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Comprobamos que las columnas clave no contienen valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que la columna id, no contiene valores nulos, para que la unión se produzca correctamente.\n",
    "print(df_csv['id_'].isnull().sum())\n",
    "print(df_excel_combined['ID'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Verificamos que las columnas clave no contienen valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De esta manera, mejoramos y optimizamos la eficiencia de nuestro set de datos\n",
    "print(df_csv.duplicated().sum())\n",
    "print(df_excel_combined.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Analizamos que el archivo excel, contiene una columna que se llama ID, la cual modificaremos el nombre a id_ , para que coincida con la del csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_combined.rename(columns={'ID': 'id_'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Decidimos hacer un merge, puesto que solo coincide una columna entre los dos archivos, y queremos traer toda la información restante. Realizamos el merge entre el dataframe csv y el de excel, a través de la columna ' id_ '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la unión a través de un outer join, puesto que queremos combinar los archivos a través de la columna id_, y que el resto de información aparezca en el resultado final.\n",
    "df = df_csv.merge(df_excel_combined, on=\"id_\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Transformamos el dataframe final en un csv, y lo creamos en la carpeta adecuada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificamos la carpeta exacta donde guardaremos el archivo\n",
    "ruta_carpeta = '../data/transform_data'\n",
    "\n",
    "# Creamos el archivo CSV en la carpeta especificada\n",
    "df.to_csv(f'{ruta_carpeta}/transform_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Realizamos el preanálisis final con las funciones que aloja Pandas, verificando que los datos se han combinado correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El .head() nos permite obtener una visualización previa de las 5 primeras filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El .info() nos aporta información sobre el tipo de dato de cada columna\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el tipo de dato de cada columna\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos si existen valores nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el número de filas y de columnas final, comprobando que no hemos perdido información\n",
    "num_filas, num_columnas = df.shape\n",
    "print(f\"El dataset combinado tiene {num_filas} filas y {num_columnas} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones del Preanálisis\n",
    "\n",
    "1. **Completitud de los datos**:<br>\n",
    "   El conjunto de datos tiene valores nulos, que deben ser reemplazados en función de la columna que corresponda (numérica o categórica),\n",
    "   para que no modifique los valores finales.<br><br>\n",
    "\n",
    "2. **Tipos de datos**:<br>\n",
    "   Las columnas clave que nos van a permitir realizar la unión, tienen el mismo tipo de dato.<br><br>\n",
    "\n",
    "3. **Duplicados**:<br>\n",
    "   No se encontraron filas duplicadas ni en el archivo, ni en las columnas clave, por lo que la unión se puede realizar correctamente.<br><br>\n",
    "\n",
    "4. **Estructura de los datos**:<br>\n",
    "   El archivo contiene **86179 filas** y **29 columnas**. Las columnas parecen ser coherentes y contienen información relevante para el análisis posterior.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

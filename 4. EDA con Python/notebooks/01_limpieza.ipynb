{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 1. Transformación y limpieza de los datos (CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Importamos pandas con el alias que decidamos y cargamos nuestro archivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/bank_additional.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Obtenemos información sobre el tipo de dato de cada columna y su previsualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El .head nos permite obtener una visualización previa de las 5 primeras filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El .info nos aporta información sobre el tipo de dato de cada columna\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el tipo de dato de cada columna\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Analizamos si existen o no valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos si existen valores duplicados\n",
    "if df.duplicated().values.any():\n",
    "    print(\"Existen valores duplicados por eliminar\")\n",
    "else:\n",
    "    print(\"No existen valores duplicados\")\n",
    "\n",
    "# Comprobamos y verificamos que no existen valores duplicados\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Analizamos y eliminamos los valores nulos existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos cuantos valores nulos existen\n",
    "print(\"Los valores nulos existentes por columna son:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazamos los valores nulos por 0\n",
    "df.fillna(0, inplace=True)\n",
    "print(\"✅ Todos los valores nulos han sido reemplazados por 0.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos si existen valores nulos\n",
    "if df.isnull().values.any():\n",
    "    print(\"❌ Todavía hay valores nulos en los datos.\")\n",
    "else:\n",
    "    print(\"✅ Todos los valores nulos han sido reemplazados por 0.\")\n",
    "\n",
    "# Comprobamos y verificamos que no existen valores nulos\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Revisamos y cambiamos el tipo de dato de cada columna que sea necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos 'age' a int\n",
    "df['age'] = df['age'].astype(int)\n",
    "\n",
    "# Convertimos 'default', 'housing', y 'loan' a bool\n",
    "df['default'] = df['default'].astype(bool)\n",
    "df['housing'] = df['housing'].astype(bool)\n",
    "df['loan'] = df['loan'].astype(bool)\n",
    "\n",
    "# Convertimos 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed' a float64. Coerce se encarga de añadir valores NaN.\n",
    "df['cons.price.idx'] = pd.to_numeric(df['cons.price.idx'], errors='coerce')\n",
    "df['cons.conf.idx'] = pd.to_numeric(df['cons.conf.idx'], errors='coerce')\n",
    "df['euribor3m'] = pd.to_numeric(df['euribor3m'], errors='coerce')\n",
    "df['nr.employed'] = pd.to_numeric(df['nr.employed'], errors='coerce')\n",
    "\n",
    "# Convertimos 'y' a bool o categoría si es binaria\n",
    "df['y'] = df['y'].map({'yes': True, 'no': False})\n",
    "\n",
    "# Convertirmos 'date' a datetime64, especificamos el formato de fecha para que no genere conflicto.\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# Convertimos 'id_' a categoría\n",
    "df['id_'] = df['id_'].astype('category')\n",
    "\n",
    "# Verificamos los tipos de datos después de los cambios\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Realizamos la estandarización de valores categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos las modificaciones solo a las columnas 'object' puesto que son las únicas que contienen texto. No tendría sentido hacerlo para columnas de tipo int, float etc\n",
    "for columna in df.select_dtypes(include=['object']).columns:\n",
    "\n",
    "# Eliminamos espacios al principio y al final, y convertimos a minúsculas para evitar conflictos\n",
    "    df[columna] = df[columna].str.strip().str.lower()\n",
    "\n",
    "# Verificamos que se aplicaron los cambios\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 2: Limpieza y Transformaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Importamos las librer√≠as necesarias y agregamos la ruta de nuestro archivo .py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Agregamos la ruta\n",
    "sys.path.append('../')\n",
    "\n",
    "# Importamos la funci√≥n procesar_dataframe de limpieza.py\n",
    "from src.limpieza import procesar_dataframe\n",
    "\n",
    "# Importamos los dos diccionarios de variables.py\n",
    "from src.variables import cambiar_nombre_columnas, cambiar_tipo_columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Cargamos el dataframe transformado, hacemos la llamada a la funci√≥n y comprobamos los cambios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el DataFrame\n",
    "df_csv = pd.read_csv('../data/transform_data/transform_Data.csv', low_memory=False)\n",
    "\n",
    "# Llamamos a la funci√≥n procesar_dataframe con los diccionarios importados\n",
    "df = procesar_dataframe(df_csv, cambiar_nombre_columnas, cambiar_tipo_columnas)\n",
    "\n",
    "# Verificamos el resultado mostrando las primeras filas\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Analizamos si existen o no valores duplicados, para poder reducir el tama√±o del archivo y mejorar la velocidad del fichero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos si existen valores duplicados\n",
    "if df.duplicated().values.any():\n",
    "    print(\"Existen valores duplicados por eliminar\")\n",
    "else:\n",
    "    print(\"No existen valores duplicados\")\n",
    "\n",
    "# Comprobamos y verificamos que no existen valores duplicados\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Analizamos si existen o no valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos cuantos valores nulos existen\n",
    "print(\"Los valores nulos existentes por columna son:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el % de nulos en cada columna, para saber la cantidad de nulos que hemos obtenido\n",
    "df.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sustituimos los nulos en las columnas num√©ricas, por la mediana de cada columna\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sustituimos los nulos en las columnas categ√≥ricas, por la moda de cada columna\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "df[categorical_columns] = df[categorical_columns].fillna(df[categorical_columns].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos que ya no hay valores nulos\n",
    "df.isnull().sum()\n",
    "\n",
    "# Verificamos algunas estad√≠sticas descriptivas despu√©s del cambio\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Realizamos la estandarizaci√≥n de valores categ√≥ricos, para evitar posibles conflictos que nos pueda causar el set de datos. Esto es √∫til a la hora de una b√∫squeda espec√≠fica de valores, que contengan espacios y causen conflicto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columna in df.select_dtypes(include=['object']).columns:\n",
    "    # Rellenar NaN con una cadena vac√≠a y luego aplicar las transformaciones\n",
    "    df[columna] = df[columna].fillna('').astype(str).str.strip().str.lower()\n",
    "\n",
    "# Verificamos que se aplicaron los cambios\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Analizamos las columnas categ√≥ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos posibles erratas o valores mal escritos, con head mostramos los 20 valores de mayor frecuencia\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    print(f\"\\nüîπ Columna: {col}\")\n",
    "    print(df_csv[col].value_counts(dropna=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos espacios en blanco, espacios dobles o caracteres\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = df[col].str.strip()\n",
    "    df[col] = df[col].replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Analizamos las columnas num√©ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos las estad√≠sticas generales\n",
    "df_csv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectamos valores fuera de rango, por ejemplo si obtenemos una edad negativa\n",
    "for col in df.select_dtypes(include=['number']).columns:\n",
    "    print(f\"\\nüîπ Columna: {col}\")\n",
    "    print(f\"Valores √∫nicos: {df[col].nunique()}\")\n",
    "    print(f\"M√°ximo: {df[col].max()}, M√≠nimo: {df[col].min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. C√°lculo del M√©todo de Rango Intercuart√≠lico (IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectamos valores bajos o altos que podr√≠an causar conflicto\n",
    "import numpy as np\n",
    "\n",
    "for col in df.select_dtypes(include=['number']).columns:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = df[(df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))]\n",
    "    print(f\"\\nüîπ Columna: {col} - Outliers encontrados: {outliers.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Guardamos el CSV con la limpieza final realizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/transform_data/bank_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
